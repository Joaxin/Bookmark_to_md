{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the netscape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<!DOCTYPE NETSCAPE-Bookmark-file-1>\n",
    "<!-- This is an automatically generated file.\n",
    "     It will be read and overwritten.\n",
    "     DO NOT EDIT! -->\n",
    "<META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=UTF-8\">\n",
    "<TITLE>Bookmarks</TITLE>\n",
    "<H1>Bookmarks</H1>\n",
    "<DL><p># Ancestors\n",
    "    <DT><H3 ADD_DATE=\"*\" LAST_MODIFIED=\"*\" PERSONAL_TOOLBAR_FOLDER=\"true\">书签栏</H3> # Ancestors' names\n",
    "    <DL><p>## Grandparents\n",
    "        <DT><H3 ADD_DATE=\"*\" LAST_MODIFIED=\"*\">\"##\"</H3> ## Grandparents' names\n",
    "        <DL><p>### Parents\n",
    "            <DT><H3 ADD_DATE=\"*\" LAST_MODIFIED=\"*\">\"###\"</H3> ### Parent1's  name\n",
    "            <DL><p>#### children\n",
    "                <DT><A HREF=\"url1\" ADD_DATE=\"*\" ICON=\"data:image/png;base64,*\">TEXT1</A>\n",
    "                <DT><A HREF=\"url2\" ADD_DATE=\"*\" ICON=\"data:image/png;base64,*\">TEXT2</A>\n",
    "                <DT><A HREF=\"url3\" ADD_DATE=\"*\" ICON=\"data:image/png;base64,*\">TEXT3</A>\n",
    "                <DT><A HREF=\"url4\" ADD_DATE=\"*\" ICON=\"data:image/png;base64,*\">TEXT4</A>\n",
    "                <DT><A HREF=\"url5\" ADD_DATE=\"*\" ICON=\"data:image/png;base64,*\">TEXT5</A>\n",
    "                .....\n",
    "            <DT><H3 ADD_DATE=\"*\" LAST_MODIFIED=\"*\">\"###\"</H3> ### Parent2's  name\n",
    "                <DT><A HREF=\"url1\" ADD_DATE=\"*\" ICON=\"data:image/png;base64,*\">TEXT1</A>\n",
    "            ......\n",
    "            </DL><p\n",
    "            .......  ### more Parents\n",
    "        </DL><p>###\n",
    "        ......   ## more Grandparents'\n",
    "    </DL><p>##\n",
    "    ......  # more Ancestors\n",
    "</DL><p>#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M is empty,  has removed\n",
      "Ani is empty, has removed.\n",
      "the http://game.ioxapp.com/ has found in ['小游戏', '小游戏'] , its a duplicated link, it's removed\n",
      "the https://www.proprofs.com/games/ has found in ['小游戏', '小游戏'] , its a duplicated link, it's removed\n",
      "the http://www.memagames.com/ has found in ['解谜', '解谜'] , its a duplicated link, it's removed\n",
      "Fetching For https://bb.kunlun.com/deeplink/\n",
      "Rename the  https://bb.kunlun.com/deeplink/  to  kunlun\n",
      "the http://www.michaelbach.de/ot/index.html has found in ['奇葩', 'ins'] , its a duplicated link, it's removed\n",
      "Fetching For http://free-line-design.com/\n",
      "Rename the  http://free-line-design.com/  to  罫線・飾り罫ライン素材 FREE LINE DESIGN | 400点以上の罫線・ライン素材がフリー（無料）でダウンロードできる「FREE LINE DESIGN」。 すぐに使える商用利用可能なjpg、png、編集可能なイラレ(ベクター)データも用意してます。\n",
      "FLAT ICON DESIGN -フラットアイコンデザイン- | フラットデザインに最適！WEBサイトやDTPですぐ使える商用利用可能なフラットアイコン素材がフリー（無料）ダウンロードできるサイト『FLAT ICON D  loaded icon but encoutered a key error\n",
      "Fetching For http://event-pre.com/\n",
      "Rename the  http://event-pre.com/  to  クリスマス・ハロウィン、お正月イラストEVENTs Design – クリスマスやハロウィン、お正月などイベント向けの無料イラスト素材配布サイト\n",
      "the http://www.zcool.com.cn/ has found in ['网站', '设计'] , its a duplicated link, it's removed\n",
      "the http://shijue.me/home has found in ['网站', '设计'] , its a duplicated link, it's removed\n",
      "the https://www.behance.net/ has found in ['pinterest', '设计'] , its a duplicated link, it's removed\n",
      "图标下载，ICON(PNG/ICO/ICNS)图标搜索下载 | EASYICON.NET  loaded icon but encoutered a key error\n",
      "Fetching For http://www.bgpatterns.com/\n",
      "Rename the  http://www.bgpatterns.com/  to  bgpatterns\n",
      "? Icon Packs  loaded icon but encoutered a key error\n",
      "Free Icons Web - Free Icons, Over 1600 Free Icon Set Download  loaded icon but encoutered a key error\n",
      "23,800 Free Icons - The Largest Icon Pack Ever | Icons8  loaded icon but encoutered a key error\n",
      "Fetching For http://www.cnbeta.com/\n",
      "Rename the  http://www.cnbeta.com/  to  cnBeta.COM - ä¸­æä¸çèµè®¯ç«\n",
      "the http://tool.chinaz.com/ has found in ['整合', '分析'] , its a duplicated link, it's removed\n",
      "the http://www.maka.im/home/index.html has found in ['工具', 'wechat'] , its a duplicated link, it's removed\n",
      "Bootstrap 字体图标(Glyphicons) | 菜鸟教程  loaded icon but encoutered a key error\n",
      "the https://www.submarinecablemap.com/ has found in ['搜索引擎', 'proxy'] , its a duplicated link, it's removed\n",
      "the https://doub.bid/sszhfx/ has found in ['搜索引擎', 'proxy'] , its a duplicated link, it's removed\n",
      "the https://zh.wikipedia.org/wiki/%E9%98%B2%E7%81%AB%E9%95%BF%E5%9F%8E has found in ['搜索引擎', 'proxy'] , its a duplicated link, it's removed\n",
      "the http://ip.zdaye.com/ has found in ['搜索引擎', 'proxy'] , its a duplicated link, it's removed\n",
      "Fetching For http://media.skysurvey.org/openzoom.html\n",
      "Request to  http://media.skysurvey.org/openzoom.html failed!!! No title found!\n",
      "Rename the  http://media.skysurvey.org/openzoom.html  to  skysurvey\n",
      "SSR is empty, has removed.\n",
      "the http://manuals.bioinformatics.ucr.edu/home/R_BioCondManual has found in ['Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the http://ftp.fau.de/ has found in ['Mirror', 'Mirror'] , its a duplicated link, it's removed\n",
      "the http://mirrors.ibiblio.org/CTAN/systems/win32/miktex/tm/packages/ has found in ['Mirror', 'Mirror'] , its a duplicated link, it's removed\n",
      "the http://mirror.lzu.edu.cn/ has found in ['Mirror', 'Mirror'] , its a duplicated link, it's removed\n",
      "the https://mirrors.tuna.tsinghua.edu.cn/ has found in ['Mirror', 'Mirror'] , its a duplicated link, it's removed\n",
      "the https://www.biostars.org/ has found in ['Bi', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://www.genome.jp/kegg/ has found in ['Bi', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://www.geneontology.org/ has found in ['Bi', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://genome.ucsc.edu/ has found in ['Bi', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://www.rna-seqblog.com/ has found in ['Bi', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://bioinformation.cn/?cat=6 has found in ['Bi', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://club.excelhome.net/thread-1177867-1-1.html has found in ['Bi', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://www.pacb.com/blog/genomes-vs-gennnnes-difference-contigs-scaffolds-genome-assemblies/ has found in ['Bi', 'Sites'] , its a duplicated link, it's removed\n",
      "新建文件夹 is empty, has removed.\n",
      "the http://www.genome.jp/kegg/ has found in ['Bi', 'Sites', 'Pathways'] , its a duplicated link, it's removed\n",
      "the https://phytozome.jgi.doe.gov/pz/portal.html# has found in ['major', 'Plants'] , its a duplicated link, it's removed\n",
      "the https://www.biostars.org/ has found in ['Bi', 'Sites', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://www.genome.jp/kegg/ has found in ['Bi', 'Sites', 'Pathways', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://www.geneontology.org/ has found in ['Bi', 'Sites', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://genome.ucsc.edu/ has found in ['Bi', 'Sites', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://www.rna-seqblog.com/ has found in ['Bi', 'Sites', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://bioinformation.cn/?cat=6 has found in ['Bi', 'Sites', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://club.excelhome.net/thread-1177867-1-1.html has found in ['Bi', 'Sites', 'Sites'] , its a duplicated link, it's removed\n",
      "the http://www.pacb.com/blog/genomes-vs-gennnnes-difference-contigs-scaffolds-genome-assemblies/ has found in ['Bi', 'Sites', 'Sites'] , its a duplicated link, it's removed\n",
      "the https://www.cottongen.org/ has found in ['Fluquor', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the https://cottonfgd.org/ has found in ['Cott', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the http://www.genome.cn/index.php has found in ['Fluquor', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the http://www.wheatgenome.org/ has found in ['Fluquor', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the https://wheat-urgi.versailles.inra.fr/ has found in ['Fluquor', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the http://plants.ensembl.org/info/website/ftp/index.html has found in ['Fluquor', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the https://www.gcbi.com.cn/gclib/html/index has found in ['Fluquor', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the http://www.arabidopsis.org/ has found in ['Fluquor', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the https://wheat.pw.usda.gov/GG3/ has found in ['Fluquor', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the https://www.rosaceae.org/ has found in ['Fluquor', 'Fluquor'] , its a duplicated link, it's removed\n",
      "the https://www.plob.org/ has found in ['Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the http://kasperdanielhansen.github.io/genbioconductor/ has found in ['Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the http://manuals.bioinformatics.ucr.edu/home/R_BioCondManual has found in ['Bi', 'Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the http://www.bioconductor.org/ has found in ['Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the https://www.tanboyu.com/ has found in ['Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the http://www.bio-info-trainee.com/ has found in ['Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the http://biotrainee.com/forum.php/ has found in ['Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the http://manuals.bioinformatics.ucr.edu/home/R_BioCondManual has found in ['Bi', 'Bi', 'Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the http://blog.csdn.net/u014801157/article/details/24372449 has found in ['Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the http://www.drive5.com/ has found in ['Bi', 'Bi'] , its a duplicated link, it's removed\n",
      "the https://cos.name/ has found in ['Stats', '统计'] , its a duplicated link, it's removed\n",
      "the http://www.xueqing.tv/ has found in ['Stats', '统计'] , its a duplicated link, it's removed\n",
      "the https://github.com/GuangchuangYu/ggtree has found in ['包', '包'] , its a duplicated link, it's removed\n",
      "the https://github.com/AliciaSchep/iheatmapr has found in ['包', '包'] , its a duplicated link, it's removed\n",
      "the https://scholar.google.com/schhp?hl=zh-CN has found in ['搜索引擎', '学术'] , its a duplicated link, it's removed\n",
      "the https://cn.aminer.org/ has found in ['搜索引擎', '学术'] , its a duplicated link, it's removed\n",
      "the http://viziometrics.org/ has found in ['搜索引擎', '学术'] , its a duplicated link, it's removed\n",
      "the http://www.chinapubmed.net/ has found in ['搜索引擎', '学术'] , its a duplicated link, it's removed\n",
      "the https://doc.plob.org/machine_learning/ has found in ['UCI', 'UCI'] , its a duplicated link, it's removed\n",
      "the http://blog.csdn.net/jiangjingxuan/article/category/6694789/1 has found in ['UCI', 'UCI'] , its a duplicated link, it's removed\n",
      "the http://archive.ics.uci.edu/ml/ has found in ['UCI', 'UCI'] , its a duplicated link, it's removed\n",
      "the http://blog.csdn.net/sp_programmer/article/category/2194667 has found in ['UCI', 'UCI'] , its a duplicated link, it's removed\n",
      "the http://www2.warwick.ac.uk/#Start-of-Something has found in ['U', 'U'] , its a duplicated link, it's removed\n",
      "the http://www.princeton.edu/~reinhard/pdfs/ has found in ['U', 'U'] , its a duplicated link, it's removed\n",
      "the http://scu.zju.edu.cn/ has found in ['U', 'U'] , its a duplicated link, it's removed\n",
      "the http://www.r-project.org/ has found in ['CRAN', 'CRAN'] , its a duplicated link, it's removed\n",
      "the http://www.rpubs.com/ has found in ['CRAN', 'CRAN'] , its a duplicated link, it's removed\n",
      "the https://rpubs.com/nishantsbi has found in ['CRAN', 'CRAN'] , its a duplicated link, it's removed\n",
      "the http://finzi.psych.upenn.edu/search.html has found in ['CRAN', 'CRAN'] , its a duplicated link, it's removed\n",
      "the http://www.statmethods.net/ has found in ['R', 'R'] , its a duplicated link, it's removed\n",
      "the http://tryr.codeschool.com/ has found in ['R', 'R'] , its a duplicated link, it's removed\n",
      "the https://www.datacamp.com/ has found in ['R', 'R'] , its a duplicated link, it's removed\n",
      "the http://www.cnblogs.com/speeding/category/569423.html has found in ['R', 'R'] , its a duplicated link, it's removed\n",
      "the http://www.cnblogs.com/steamed-bread/p/5416872.html has found in ['R', 'R'] , its a duplicated link, it's removed\n",
      "the http://www.cookbook-r.com/Graphs/ has found in ['R', 'R'] , its a duplicated link, it's removed\n",
      "the http://blog.csdn.net/xxzhangx has found in ['R', 'R'] , its a duplicated link, it's removed\n",
      "the http://www.rprogramming.info/ has found in ['R', 'R'] , its a duplicated link, it's removed\n",
      "the https://www.programiz.com/r-programming has found in ['R', 'R'] , its a duplicated link, it's removed\n",
      "the http://www.rwdc2.com/ has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://vincebuffalo.org/ has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the https://sakai.duke.edu/access/content/group/7a48cfac-b05c-4291-8e13-0091b5cd1479/Reference/DESeq2Notebook.html has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://www.rwdc2.com/files/bioconductor.html has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://genomicsclass.github.io/book/ has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the https://yufree.cn/ has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://jingyan.baidu.com/user/npublic/?un=AAA3381664&pn=0 has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://scu.zju.edu.cn/redir.php?catalog_id=58400&page=0 has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the https://github.com/GuangchuangYu has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://blog.qiubio.com:8080/ has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://zjuwhw.github.io/2016/08/13/fastq_format.html has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://guangchuangyu.github.io/ has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://blog.csdn.net/msw521sg/article/category/6389606 has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://www.cnblogs.com/nxld/ has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://www.360doc.com/userhome/19913717 has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://www.cnblogs.com/vamei/ has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the http://www.ruanyifeng.com/blog/ has found in ['Blogs', 'Blogs'] , its a duplicated link, it's removed\n",
      "the https://www.rdocumentation.org/packages/BSgenome/versions/1.40.1 has found in ['Docs', 'Docs'] , its a duplicated link, it's removed\n",
      "the http://blog.sciencenet.cn/blog-430956-917432.html has found in ['Docs', 'Docs'] , its a duplicated link, it's removed\n",
      "the http://combine-australia.github.io/RNAseq-R/ has found in ['Docs', 'Docs'] , its a duplicated link, it's removed\n",
      "the file:///G:/R/Bioconductor/RNA-seq/EDA%20of%20gene%20counts/rnaseq_gene_level.html has found in ['Docs', 'Docs'] , its a duplicated link, it's removed\n",
      "the http://www.omicshare.com/tools/Home/Index/index.html has found in ['fg', 'fg'] , its a duplicated link, it's removed\n",
      "the http://www.zhihu.com/question/23698905 has found in ['li', 'Art'] , its a duplicated link, it's removed\n",
      "the http://edu.163.com/edu2004/editor_2004/language/040510/040510_136775.html has found in ['li', 'Art'] , its a duplicated link, it's removed\n",
      "the http://www.guokr.com/post/404819/ has found in ['li', 'Art'] , its a duplicated link, it's removed\n",
      "the https://www.wikiart.org/ has found in ['li', 'Art'] , its a duplicated link, it's removed\n",
      "the https://www.artsy.net/artists has found in ['li', 'Art'] , its a duplicated link, it's removed\n",
      "cc is empty, has removed.\n",
      "795\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from requests import RequestException\n",
    "\n",
    "links = {}\n",
    "\n",
    "def Fetching(url):\n",
    "    s = requests.Session()\n",
    "    try:\n",
    "        r = s.get(url, allow_redirects=True)\n",
    "        title = BeautifulSoup(r.text,\"lxml\").title\n",
    "        if r.status_code == 200 and title:\n",
    "            return title.string\n",
    "        elif title is None:\n",
    "            print('Request to ', url, \"failed!!!\", 'No title found!')\n",
    "        else:\n",
    "            if response.history:\n",
    "                print(\"Request was redirected to \", r.url)\n",
    "                rr = s.get(r.url)\n",
    "                if rr.status_code == 200:\n",
    "                    return BeautifulSoup(rr.text,\"lxml\").title.string\n",
    "    except RequestException:\n",
    "        print('Request to ', url, \"failed!!!\")\n",
    "\n",
    "def bookmarks_to_md(Netscape_file, connection = True):\n",
    "    for element in Netscape_file:\n",
    "        if element.name == 'dt':\n",
    "            folder_title = element.find('h3', recursive=False)\n",
    "            if folder_title:\n",
    "                if folder_title.parent.a is None:   ## empty folders\n",
    "                    print(folder_title.string ,'is empty, has removed.')\n",
    "                else:\n",
    "                    f.write('\\n###  ' + folder_title.string + \"\\n\")\n",
    "                    folder = element.dt.find('a', recursive=False)\n",
    "                    if folder:\n",
    "                        for a in element.find_all('a'):\n",
    "                            if a['href'] in links:\n",
    "                                links[a['href']].append(str(folder_title.string))\n",
    "                                print(\"the %s has found in %s , its a duplicated link, it's removed\" \\\n",
    "                                          %(a['href'],links[a['href']]))\n",
    "                            else:\n",
    "                                    links[a['href']]= [folder_title.string]\n",
    "                                    if re.match(\"http://|https://\",a.string): ## blank titles\n",
    "                                        title =  re.sub(\".*://.*?\\.(.*?)\\..*\",'\\\\1',a['href'])\n",
    "                                        if connection:\n",
    "                                            print('Fetching For',a['href'],)\n",
    "                                            temp_title = Fetching(a['href'])\n",
    "                                            if temp_title is None:\n",
    "                                                print('Rename the ',a.string, ' to ', title)\n",
    "                                            else:\n",
    "                                                print('Rename the ',a.string, ' to ', temp_title)\n",
    "                                                title = temp_title\n",
    "                                        else:\n",
    "                                            print('Rename the ',a.string, ' to ', title)\n",
    "                                        f.write(\"[{0}]({1})\\n\".format(title,a['href']))\n",
    "                                    else:\n",
    "        #                                 print(a.string)\n",
    "        #                                 print(a['href'])\n",
    "                                        if re.search(\"icon\",str(a),re.S):\n",
    "                                            try:\n",
    "                                                f.write(\"[{0}]:{1}\\n\".format(a.string,a['icon']))\n",
    "                                                f.write(\"![icon][{0}][{1}]({2})\\n\" .format(a.string,a.string,a['href']))\n",
    "                                            except KeyError:\n",
    "                                                print(a.string,\" loaded icon but encoutered a key error\")\n",
    "                                                f.write(\"[{0}]({1})\\n\".format(a.string,a['href']))\n",
    "                                        else:\n",
    "                                            f.write(\"[{0}]({1})\\n\".format(a.string,a['href']))\n",
    "                    else:\n",
    "                        return bookmarks_to_md(element,connection = connection)\n",
    "            elif element.find('a', recursive=False):  ### isolate links\n",
    "                s =element.find('a', recursive=False).string\n",
    "                url = element.find('a', recursive=False)['href']\n",
    "                f.write(\"[{0}]({1})\\n\".format(s,url))\n",
    "#                 print(element.find('a', recursive=False).string)\n",
    "#                 print(element.find('a', recursive=False)['href'])\n",
    "        elif element.name=='a':  ## outside links\n",
    "#             print(element.string)\n",
    "#             print(element['href'])\n",
    "              f.write(\"[{0}]({1})\\n\".format(element.string,element['href']))\n",
    "\n",
    "\n",
    "def write_to_md(file,connection=True):\n",
    "    with open(file,encoding='utf-8') as fl:\n",
    "        soup = BeautifulSoup(fl,\"html5lib\").body.dt\n",
    "        for p in soup.find_all('p'):\n",
    "            p.unwrap()\n",
    "        for dl in soup.find_all('dl'):\n",
    "            dl.unwrap()\n",
    "        # print(soup.prettify())\n",
    "        fl.close()\n",
    "        for title in soup.find_all('dt',recursive=False):\n",
    "            if title.find(\"h3\"):\n",
    "                if title.a is None:   ## empty folders\n",
    "                    print(title.h3.string ,'is empty,  has removed')\n",
    "                else:\n",
    "                    f.write(\"\\n##  \"  + title.find(\"h3\").string)\n",
    "                    f.write('\\n---\\n')\n",
    "                    bookmarks_to_md(title,connection=connection)\n",
    "       \n",
    "with open(\"Bookmarks.md\",\"w\",encoding='utf-8') as f:        \n",
    "    write_to_md(\"C:/Users/Lyole/Desktop/bookmarks_2018_3_17.html\")\n",
    "    print(len(links))\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
